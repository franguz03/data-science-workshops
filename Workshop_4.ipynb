{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WorkShop 4\n",
    "\n",
    "It is the time to be a Machine Learning Engineer. Pay a lot of attention for instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1\n",
    "\n",
    "For this assignment, you will be using the _Breast Cancer Wisconsin_ (Diagnostic) Database to create a classifier that can help diagnose patients. First, read through the description of the dataset (below).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 569\n",
      "\n",
      ":Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      ":Attribute Information:\n",
      "    - radius (mean of distances from center to points on the perimeter)\n",
      "    - texture (standard deviation of gray-scale values)\n",
      "    - perimeter\n",
      "    - area\n",
      "    - smoothness (local variation in radius lengths)\n",
      "    - compactness (perimeter^2 / area - 1.0)\n",
      "    - concavity (severity of concave portions of the contour)\n",
      "    - concave points (number of concave portions of the contour)\n",
      "    - symmetry\n",
      "    - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "    The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "    worst/largest values) of these features were computed for each image,\n",
      "    resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "    10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "    - class:\n",
      "            - WDBC-Malignant\n",
      "            - WDBC-Benign\n",
      "\n",
      ":Summary Statistics:\n",
      "\n",
      "===================================== ====== ======\n",
      "                                        Min    Max\n",
      "===================================== ====== ======\n",
      "radius (mean):                        6.981  28.11\n",
      "texture (mean):                       9.71   39.28\n",
      "perimeter (mean):                     43.79  188.5\n",
      "area (mean):                          143.5  2501.0\n",
      "smoothness (mean):                    0.053  0.163\n",
      "compactness (mean):                   0.019  0.345\n",
      "concavity (mean):                     0.0    0.427\n",
      "concave points (mean):                0.0    0.201\n",
      "symmetry (mean):                      0.106  0.304\n",
      "fractal dimension (mean):             0.05   0.097\n",
      "radius (standard error):              0.112  2.873\n",
      "texture (standard error):             0.36   4.885\n",
      "perimeter (standard error):           0.757  21.98\n",
      "area (standard error):                6.802  542.2\n",
      "smoothness (standard error):          0.002  0.031\n",
      "compactness (standard error):         0.002  0.135\n",
      "concavity (standard error):           0.0    0.396\n",
      "concave points (standard error):      0.0    0.053\n",
      "symmetry (standard error):            0.008  0.079\n",
      "fractal dimension (standard error):   0.001  0.03\n",
      "radius (worst):                       7.93   36.04\n",
      "texture (worst):                      12.02  49.54\n",
      "perimeter (worst):                    50.41  251.2\n",
      "area (worst):                         185.2  4254.0\n",
      "smoothness (worst):                   0.071  0.223\n",
      "compactness (worst):                  0.027  1.058\n",
      "concavity (worst):                    0.0    1.252\n",
      "concave points (worst):               0.0    0.291\n",
      "symmetry (worst):                     0.156  0.664\n",
      "fractal dimension (worst):            0.055  0.208\n",
      "===================================== ====== ======\n",
      "\n",
      ":Missing Attribute Values: None\n",
      "\n",
      ":Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      ":Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      ":Donor: Nick Street\n",
      "\n",
      ":Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. dropdown:: References\n",
      "\n",
      "  - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction\n",
      "    for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on\n",
      "    Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "    San Jose, CA, 1993.\n",
      "  - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and\n",
      "    prognosis via linear programming. Operations Research, 43(4), pages 570-577,\n",
      "    July-August 1995.\n",
      "  - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "    to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994)\n",
      "    163-171.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.1\n",
    "\n",
    "_Scikit-learn_ works with lists, numpy arrays, scipy-sparse matrices, and pandas DataFrames, so converting the dataset to a DataFrame is not necessary for training this model. Using a _DataFrame_ does however help make many things easier such as munging data, so let's practice creating a classifier with a pandas DataFrame. \n",
    "\n",
    "\n",
    "Convert the sklearn.dataset `cancer` to a DataFrame. \n",
    "\n",
    "_This function should return a_ `(569, 31)` _DataFrame with:_\n",
    "\n",
    "```\n",
    "columns = \n",
    "    ['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
    "    'mean smoothness', 'mean compactness', 'mean concavity',\n",
    "    'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
    "    'radius error', 'texture error', 'perimeter error', 'area error',\n",
    "    'smoothness error', 'compactness error', 'concavity error',\n",
    "    'concave points error', 'symmetry error', 'fractal dimension error',\n",
    "    'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
    "    'worst smoothness', 'worst compactness', 'worst concavity',\n",
    "    'worst concave points', 'worst symmetry', 'worst fractal dimension',\n",
    "    'target']\n",
    "\n",
    "index = RangeIndex(start=0, stop=569, step=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_one():\n",
    "    index = pd.RangeIndex(start=0, stop=569, step=1);\n",
    "    data = pd.DataFrame(cancer.data, columns=[cancer.feature_names],index=index)\n",
    "    data['target'] = pd.Series(data=cancer.target, index=data.index)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 31)\n"
     ]
    }
   ],
   "source": [
    "print(answer_one().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for professor tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.2\n",
    "\n",
    "What is the class distribution? (i.e. how many instances of `malignant` and how many `benign`?)\n",
    "\n",
    "_This function should return a Series named `target` of length 2 with integer values and index =_ `['malignant', 'benign']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_two():\n",
    "    cancerdf = answer_one()\n",
    "    \n",
    "    index = ['malignant', 'benign']\n",
    "    malignant = np.where(cancerdf['target'] == 0.0);\n",
    "    benign = np.where(cancerdf['target'] == 1.0);\n",
    "    data1 = [np.size(malignant), np.size(benign)]\n",
    "    \n",
    "    \n",
    "    target=pd.Series(data1,index=index)\n",
    "    \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malignant    424\n",
      "benign       714\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(answer_two())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for professor tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.3\n",
    "\n",
    "Split the DataFrame into `X` (the data) and `y` (the labels).\n",
    "\n",
    "_This function should return a tuple of length 2: `(X, y)`, where:_\n",
    "\n",
    "- _`X` has shape `(569, 30)`_\n",
    "- _`y` has shape `(569,)`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_three():\n",
    "    cancerdf = answer_one()\n",
    "    X = cancerdf.drop('target', axis=1)\n",
    "    y = cancerdf.get('target')\n",
    "    \n",
    "    return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) (569, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\57300\\AppData\\Local\\Temp\\ipykernel_5288\\4055544598.py:3: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  X = cancerdf.drop('target', axis=1)\n"
     ]
    }
   ],
   "source": [
    "x,y=answer_three()\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for professor tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.4\n",
    "\n",
    "Using `train_test_split`, split `X` and `y` into training and test sets `(X_train, X_test, y_train, and y_test)`.\n",
    "\n",
    "__Set the random number generator state to 0 using `random_state=0` to make sure your results match the autograder!__\n",
    "\n",
    "_This function should return a tuple of length 4: `(X_train, X_test, y_train, y_test)`, where:_\n",
    "\n",
    "- _`X_train` has shape `(426, 30)`_\n",
    "- _`X_test` has shape `(143, 30)`_\n",
    "- _`y_train` has shape `(426,)`_\n",
    "- _`y_test` has shape `(143,)`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def answer_four():\n",
    "    X, y = answer_three()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30) (143, 30) (426, 1) (143, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\57300\\AppData\\Local\\Temp\\ipykernel_5288\\4055544598.py:3: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  X = cancerdf.drop('target', axis=1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test=answer_four()\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for professor tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.5\n",
    "\n",
    "Using KNeighborsClassifier, fit a k-nearest neighbors (knn) classifier with `X_train`, `y_train` and using one nearest neighbor (`n_neighbors = 1`).\n",
    "\n",
    "_This function should return a `sklearn.neighbors.classification.KNeighborsClassifier`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def answer_five():\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "    knn.fit(X_train, y_train)\n",
    "    knn.score(X_test, y_test)\n",
    "    \n",
    "    return knn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\57300\\AppData\\Local\\Temp\\ipykernel_5288\\4055544598.py:3: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  X = cancerdf.drop('target', axis=1)\n",
      "c:\\Users\\57300\\Desktop\\datascience\\ud-public\\courses\\data-science-introduction\\notebooks\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "print (type(answer_five()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for professor tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.6\n",
    "\n",
    "Using your __knn classifier__, predict the class label using the mean value for each feature.\n",
    "\n",
    "___Hint:___ _You can use `cancer_df.mean()[:-1].values.reshape(1, -1)` which gets the mean value for each feature, ignores the target column, and reshapes the data from 1 dimension to 2 (necessary for the precict method of KNeighborsClassifier)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_six():\n",
    "    cancerdf = answer_one()\n",
    "    means = cancerdf.mean()[:-1].values.reshape(1, -1)\n",
    "    knn = answer_five()\n",
    "    \n",
    "    return knn.predict(means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\57300\\AppData\\Local\\Temp\\ipykernel_5288\\4055544598.py:3: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  X = cancerdf.drop('target', axis=1)\n",
      "c:\\Users\\57300\\Desktop\\datascience\\ud-public\\courses\\data-science-introduction\\notebooks\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "print(answer_six())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for professor tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.7\n",
    "\n",
    "Using your __knn classifier__, predict the class labels for the test set `X_test`.\n",
    "\n",
    "_This function should return a numpy array with shape `(143,)` and values either `0.0` or `1.0`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_seven():\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    knn = answer_five()\n",
    "    test_prediction = knn.predict(X_test)\n",
    "    return test_prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\57300\\AppData\\Local\\Temp\\ipykernel_5288\\4055544598.py:3: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  X = cancerdf.drop('target', axis=1)\n",
      "C:\\Users\\57300\\AppData\\Local\\Temp\\ipykernel_5288\\4055544598.py:3: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  X = cancerdf.drop('target', axis=1)\n",
      "c:\\Users\\57300\\Desktop\\datascience\\ud-public\\courses\\data-science-introduction\\notebooks\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "predictions = answer_seven()\n",
    "assert predictions.shape == (143,)\n",
    "assert np.all((0.0 <= predictions) & (predictions <= 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for professor tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.8\n",
    "\n",
    "Find the score (_mean accuracy_) of your __knn classifier__ using `X_test` and `y_test`.\n",
    "\n",
    "_This function should return a float between $0$ and $1$._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_eight():\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    knn = answer_five()\n",
    "    score = knn.score(X_test, y_test)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\57300\\AppData\\Local\\Temp\\ipykernel_5288\\4055544598.py:3: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  X = cancerdf.drop('target', axis=1)\n",
      "C:\\Users\\57300\\AppData\\Local\\Temp\\ipykernel_5288\\4055544598.py:3: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  X = cancerdf.drop('target', axis=1)\n",
      "c:\\Users\\57300\\Desktop\\datascience\\ud-public\\courses\\data-science-introduction\\notebooks\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "score = answer_eight()\n",
    "assert type(score) ==float\n",
    "assert int(score) >= 0 & int(score) <=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for professor tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.9\n",
    "\n",
    "Using the plotting function below to visualize the different predicition scores between _train_ and _test sets_, as well as malignant and benign cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\57300\\AppData\\Local\\Temp\\ipykernel_5288\\4055544598.py:3: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  X = cancerdf.drop('target', axis=1)\n",
      "C:\\Users\\57300\\AppData\\Local\\Temp\\ipykernel_5288\\4055544598.py:3: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  X = cancerdf.drop('target', axis=1)\n",
      "c:\\Users\\57300\\Desktop\\datascience\\ud-public\\courses\\data-science-introduction\\notebooks\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def answer_nine():\n",
    "\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "\n",
    "    # Ensure y_train and y_test are 1D arrays\n",
    "    y_train = np.ravel(y_train)\n",
    "    y_test = np.ravel(y_test)\n",
    "\n",
    "    # Fill NaN values with the mean of each column\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "    X_test = imputer.transform(X_test)\n",
    "\n",
    "    # Find the training and testing accuracies by target value (i.e. malignant, benign)\n",
    "    mal_train_X = X_train[y_train == 0]\n",
    "    mal_train_y = y_train[y_train == 0]\n",
    "    ben_train_X = X_train[y_train == 1]\n",
    "    ben_train_y = y_train[y_train == 1]\n",
    "\n",
    "    mal_test_X = X_test[y_test == 0]\n",
    "    mal_test_y = y_test[y_test == 0]\n",
    "    ben_test_X = X_test[y_test == 1]\n",
    "    ben_test_y = y_test[y_test == 1]\n",
    "\n",
    "    knn = answer_five()\n",
    "\n",
    "    scores = [knn.score(mal_train_X, mal_train_y), knn.score(ben_train_X, ben_train_y),\n",
    "              knn.score(mal_test_X, mal_test_y), knn.score(ben_test_X, ben_test_y)]\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    bars = plt.bar(np.arange(4), scores, color=['blue', 'blue', 'green', 'green'])\n",
    "\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.gca().text(bar.get_x() + bar.get_width()/2, height*.90, '{0:.{1}f}'.format(height, 2),\n",
    "                       ha='center', color='w', fontsize=11)\n",
    "\n",
    "answer_nine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2\n",
    "\n",
    "In this case, you are going to use a _.csv_ dataset to evaluate some performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depencencies\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.1\n",
    "\n",
    "Import the data from `assets/fraud_data.csv`. What percentage of the observations in the dataset are instances of fraud?\n",
    "\n",
    "_This function should return a float between $0$ and $1$._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_eleven():\n",
    "    fraud_df = pd.read_csv('./assets/fraud_data.csv')\n",
    "    \n",
    "    \n",
    "    return len(fraud_df[fraud_df.Class ==1])/len(fraud_df[\"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016410823768035772\n"
     ]
    }
   ],
   "source": [
    "percentage=answer_eleven()\n",
    "assert type(percentage) ==float\n",
    "assert int(percentage) >= 0 & int(score) <=1\n",
    "print(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for professor tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use X_train, X_test, y_train, y_test for all of the following questions\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('assets/fraud_data.csv')\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.2\n",
    "\n",
    "Using `X_train`, `X_test`, `y_train`, and `y_test` (as defined above), train a dummy classifier that classifies everything as the majority class of the training data. What is the accuracy of this classifier? What is the recall?\n",
    "\n",
    "_This function should a return a tuple with two floats, i.e. `(accuracy score, recall score)`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import recall_score,accuracy_score\n",
    "\n",
    "def answer_twelve():\n",
    "    dummy = DummyClassifier(strategy='most_frequent')\n",
    "    \n",
    "    dummy.fit(X_train, y_train)\n",
    "    \n",
    "    y_hat = dummy.predict(X_test)\n",
    "    \n",
    "    return (accuracy_score(y_hat, y_test), recall_score(y_hat, y_test))\n",
    "\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9852507374631269 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\57300\\Desktop\\datascience\\ud-public\\courses\\data-science-introduction\\notebooks\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy, recall = answer_twelve()\n",
    "\n",
    "assert isinstance(accuracy, float)\n",
    "assert isinstance(recall, float)\n",
    "assert 0 <= accuracy <= 1\n",
    "assert 0 <= recall <= 1\n",
    "print(accuracy, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for professor tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.3\n",
    "\n",
    "Using `X_train`, `X_test`, `y_train`, and `y_test` (as defined above), train a _XGBoost_ classifer using the default parameters. What is the accuracy, recall, precision, and F1 Score of this classifier?\n",
    "\n",
    "_This function should a return a tuple with three floats, i.e. `(accuracy score, recall score, precision score, f1 score)`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\57300\\desktop\\datascience\\ud-public\\courses\\data-science-introduction\\notebooks\\.venv\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\57300\\desktop\\datascience\\ud-public\\courses\\data-science-introduction\\notebooks\\.venv\\lib\\site-packages (from xgboost) (1.26.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\57300\\desktop\\datascience\\ud-public\\courses\\data-science-introduction\\notebooks\\.venv\\lib\\site-packages (from xgboost) (1.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "def answer_thirteen():\n",
    "\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "\n",
    "    y_hat = model.predict(X_test)\n",
    "    \n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_hat)\n",
    "    recall = recall_score(y_test, y_hat)\n",
    "    precision = precision_score(y_test, y_hat)\n",
    "    f1 = f1_score(y_test, y_hat)\n",
    "    \n",
    "    return (accuracy, recall, precision, f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, recall, precision, f1 = answer_thirteen()\n",
    "\n",
    "assert isinstance(accuracy, float), \"Accuracy should be a float\"\n",
    "assert isinstance(recall, float), \"Recall should be a float\"\n",
    "assert isinstance(precision, float), \"Precision should be a float\"\n",
    "assert isinstance(f1, float), \"F1 score should be a float\"\n",
    "\n",
    "assert 0 <= accuracy <= 1, f\"Accuracy {accuracy} should be between 0 and 1\"\n",
    "assert 0 <= recall <= 1, f\"Recall {recall} should be between 0 and 1\"\n",
    "assert 0 <= precision <= 1, f\"Precision {precision} should be between 0 and 1\"\n",
    "assert 0 <= f1 <= 1, f\"F1 score {f1} should be between 0 and 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for professor tests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "class-example",
   "language": "python",
   "name": "class_example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
